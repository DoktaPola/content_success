{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548d1add-0c9a-421f-8d2d-55af29b40dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de9e5d68-644c-4f90-adca-78b14178302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "696700fc-5134-4dee-9979-874d074c233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/work/item_coldstart_dataset.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "78ed2289-80d7-418e-842d-84793b3f15fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>age_access_type</th>\n",
       "      <th>country</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>availability</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genre</th>\n",
       "      <th>director</th>\n",
       "      <th>target</th>\n",
       "      <th>subscription_only</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cff3362f-ad91-498d-80b3-ea3ab8ec65cf, 21c7a45...</td>\n",
       "      <td>12</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6420000</td>\n",
       "      <td>[DTO, RENT, SUBSCRIPTION]</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Звёздный путь 5: Последний рубеж</td>\n",
       "      <td>1989</td>\n",
       "      <td>[Sci-Fi, Action, Thriller, Adventure]</td>\n",
       "      <td>[cff3362f-ad91-498d-80b3-ea3ab8ec65cf]</td>\n",
       "      <td>8.508657e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>e785baa6-f175-42b4-9e16-4319ac7991d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cff3362f-ad91-498d-80b3-ea3ab8ec65cf, 21c7a45...</td>\n",
       "      <td>16</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6780000</td>\n",
       "      <td>[DTO, RENT, SUBSCRIPTION]</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Звёздный путь 6: Неоткрытая страна</td>\n",
       "      <td>1991</td>\n",
       "      <td>[Sci-Fi, Action, Thriller, Adventure]</td>\n",
       "      <td>[bab6b7f4-4506-458f-9091-d567505674f2]</td>\n",
       "      <td>1.559920e-06</td>\n",
       "      <td>False</td>\n",
       "      <td>4593737e-de9c-40df-97db-fb3cf85a08ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cff3362f-ad91-498d-80b3-ea3ab8ec65cf, bcad17e...</td>\n",
       "      <td>18</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6000000</td>\n",
       "      <td>[DTO, RENT, SUBSCRIPTION]</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>В поисках древнего артефакта</td>\n",
       "      <td>2019</td>\n",
       "      <td>[Horror]</td>\n",
       "      <td>[895f5774-964a-4c5a-ae22-d697d3e3e620]</td>\n",
       "      <td>3.578051e-06</td>\n",
       "      <td>False</td>\n",
       "      <td>11ba66db-e941-4c3a-8da6-d8900e56f8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cff3362f-ad91-498d-80b3-ea3ab8ec65cf, 30dd19c...</td>\n",
       "      <td>18</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>6.99</td>\n",
       "      <td>3780000</td>\n",
       "      <td>[SUBSCRIPTION]</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Прожарка Чарли Шина</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Comedy, Documentary]</td>\n",
       "      <td>[1de22aff-430e-4af9-bf1d-159dbf8e9269]</td>\n",
       "      <td>3.544765e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>3f30a2ef-53b7-40e3-954f-1bdfc38a6d17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[cff3362f-ad91-498d-80b3-ea3ab8ec65cf, a805fdd...</td>\n",
       "      <td>18</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3780000</td>\n",
       "      <td>[SUBSCRIPTION]</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Прожарка Уильяма Шэтнера</td>\n",
       "      <td>2006</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>[1de22aff-430e-4af9-bf1d-159dbf8e9269]</td>\n",
       "      <td>6.394210e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>cdfa700f-122d-41e5-b8dc-9c6813bab6d2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               actor age_access_type country  \\\n",
       "0  [cff3362f-ad91-498d-80b3-ea3ab8ec65cf, 21c7a45...              12   [usa]   \n",
       "1  [cff3362f-ad91-498d-80b3-ea3ab8ec65cf, 21c7a45...              16   [usa]   \n",
       "2  [cff3362f-ad91-498d-80b3-ea3ab8ec65cf, bcad17e...              18   [usa]   \n",
       "3  [cff3362f-ad91-498d-80b3-ea3ab8ec65cf, 30dd19c...              18   [usa]   \n",
       "4  [cff3362f-ad91-498d-80b3-ea3ab8ec65cf, a805fdd...              18   [usa]   \n",
       "\n",
       "  average_rating duration               availability   type  \\\n",
       "0           6.21  6420000  [DTO, RENT, SUBSCRIPTION]  MOVIE   \n",
       "1            7.2  6780000  [DTO, RENT, SUBSCRIPTION]  MOVIE   \n",
       "2            4.0  6000000  [DTO, RENT, SUBSCRIPTION]  MOVIE   \n",
       "3           6.99  3780000             [SUBSCRIPTION]  MOVIE   \n",
       "4            6.0  3780000             [SUBSCRIPTION]  MOVIE   \n",
       "\n",
       "                                 name release_year  \\\n",
       "0    Звёздный путь 5: Последний рубеж         1989   \n",
       "1  Звёздный путь 6: Неоткрытая страна         1991   \n",
       "2        В поисках древнего артефакта         2019   \n",
       "3                 Прожарка Чарли Шина         2011   \n",
       "4            Прожарка Уильяма Шэтнера         2006   \n",
       "\n",
       "                                   genre  \\\n",
       "0  [Sci-Fi, Action, Thriller, Adventure]   \n",
       "1  [Sci-Fi, Action, Thriller, Adventure]   \n",
       "2                               [Horror]   \n",
       "3                  [Comedy, Documentary]   \n",
       "4                               [Comedy]   \n",
       "\n",
       "                                 director        target subscription_only  \\\n",
       "0  [cff3362f-ad91-498d-80b3-ea3ab8ec65cf]  8.508657e-07             False   \n",
       "1  [bab6b7f4-4506-458f-9091-d567505674f2]  1.559920e-06             False   \n",
       "2  [895f5774-964a-4c5a-ae22-d697d3e3e620]  3.578051e-06             False   \n",
       "3  [1de22aff-430e-4af9-bf1d-159dbf8e9269]  3.544765e-04              True   \n",
       "4  [1de22aff-430e-4af9-bf1d-159dbf8e9269]  6.394210e-05              True   \n",
       "\n",
       "                                    uid  \n",
       "0  e785baa6-f175-42b4-9e16-4319ac7991d5  \n",
       "1  4593737e-de9c-40df-97db-fb3cf85a08ef  \n",
       "2  11ba66db-e941-4c3a-8da6-d8900e56f8c7  \n",
       "3  3f30a2ef-53b7-40e3-954f-1bdfc38a6d17  \n",
       "4  cdfa700f-122d-41e5-b8dc-9c6813bab6d2  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d151c5e4-07a8-41a1-9ec6-b3514862e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['actor', 'age_access_type', 'country', 'average_rating', 'duration',\n",
       "       'availability', 'type', 'name', 'release_year', 'genre', 'director',\n",
       "       'target', 'subscription_only', 'uid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "163abcf6-40a3-445d-93ee-0f8b70689eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11917, 14)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3007db0a-cd9c-45d1-86d9-93be128045db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([2408, 2446], axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fea520-e62e-4d3e-9e20-71cae8529285",
   "metadata": {},
   "source": [
    "# Step for model 3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0caf2bf1-bf06-42ba-bbce-6a247cf89a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>age_access_type</th>\n",
       "      <th>country</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>availability</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genre</th>\n",
       "      <th>director</th>\n",
       "      <th>target</th>\n",
       "      <th>subscription_only</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cff3362f-ad91-498d-80b3-ea3ab8ec65cf, 21c7a45...</td>\n",
       "      <td>12</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>6.21</td>\n",
       "      <td>6420000</td>\n",
       "      <td>[DTO, RENT, SUBSCRIPTION]</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Звёздный путь 5: Последний рубеж</td>\n",
       "      <td>1989</td>\n",
       "      <td>[Sci-Fi, Action, Thriller, Adventure]</td>\n",
       "      <td>[cff3362f-ad91-498d-80b3-ea3ab8ec65cf]</td>\n",
       "      <td>8.508657e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>e785baa6-f175-42b4-9e16-4319ac7991d5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               actor age_access_type country  \\\n",
       "0  [cff3362f-ad91-498d-80b3-ea3ab8ec65cf, 21c7a45...              12   [usa]   \n",
       "\n",
       "  average_rating duration               availability   type  \\\n",
       "0           6.21  6420000  [DTO, RENT, SUBSCRIPTION]  MOVIE   \n",
       "\n",
       "                               name release_year  \\\n",
       "0  Звёздный путь 5: Последний рубеж         1989   \n",
       "\n",
       "                                   genre  \\\n",
       "0  [Sci-Fi, Action, Thriller, Adventure]   \n",
       "\n",
       "                                 director        target subscription_only  \\\n",
       "0  [cff3362f-ad91-498d-80b3-ea3ab8ec65cf]  8.508657e-07             False   \n",
       "\n",
       "                                    uid  \n",
       "0  e785baa6-f175-42b4-9e16-4319ac7991d5  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cb7ef03-cb58-4f12-bf78-9c5b5c21eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = []\n",
    "\n",
    "for values in df['actor']:\n",
    "    actors.extend(values)\n",
    "    \n",
    "actors_count = Counter(actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "049c8e79-f354-4e2f-9730-ada8b5ffd1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34027"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actors_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f676efb-56cb-4266-a165-6753a9f43c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_count_1 = [actor for actor, c in actors_count.items() if c < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72b0bf60-6a3a-46c7-8e44-7e708755d0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23878"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actors_count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a1d540-5a10-45b3-8e4f-2a888f5695d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from random import choices\n",
    "\n",
    "mltpl_cat_features = ['actor', 'country', 'genre', 'director']\n",
    "cat_features = ['availability']\n",
    "cat_features_raw = ['type', 'subscription_only']\n",
    "num_features = ['age_access_type', 'average_rating', 'duration', 'release_year']\n",
    "skewed_num_features = ['duration']\n",
    "text_features = ['name']\n",
    "mltpl_cat_n_top = {'actor': 5, 'country': 1, 'genre': 3, 'director': 1}\n",
    "\n",
    "\n",
    "class Cat2Vec:\n",
    "    def __init__(self, n_cat2vec_feature,\n",
    "                    n_cat2vec_window,\n",
    "                    min_count=1):\n",
    "        self.n_cat2vec_feature = n_cat2vec_feature\n",
    "        self.n_cat2vec_window = n_cat2vec_window\n",
    "        self.min_count = min_count\n",
    "    \n",
    "    def __create_tokens(self, col_name, values):\n",
    "        return [f'{col_name} {value}' for value in values]\n",
    "    \n",
    "    def __gen_cat2vec_sentences(self, data):\n",
    "        items = []\n",
    "\n",
    "        for i, row in data.iterrows():\n",
    "            item_values = []\n",
    "            for col, values in zip(row.index, row.values):\n",
    "                item_values.extend(self.__create_tokens(col, values))\n",
    "            # shuffle(item_values)\n",
    "            items.append(item_values)\n",
    "        return items\n",
    "    \n",
    "    def fit(self, cat_features):\n",
    "        X_w2v = self.__gen_cat2vec_sentences(cat_features)\n",
    "        self.model = Word2Vec(X_w2v, vector_size=self.n_cat2vec_feature, \n",
    "                         window=self.n_cat2vec_window, epochs=5, min_count=self.min_count)\n",
    "        \n",
    "    def transform(self, cat_features):\n",
    "        encoded_features = pd.DataFrame()\n",
    "        for col in cat_features.columns:\n",
    "            tokens = [self.__create_tokens(col, row) for row in cat_features[col]]\n",
    "            col_embeds = []\n",
    "            for row in tokens:\n",
    "                avg_embeds = np.mean([self.model.wv[token] for token in row if token in self.model.wv.key_to_index], \n",
    "                                          axis=0)\n",
    "                if isinstance(avg_embeds, np.float64):\n",
    "                    avg_embeds = [np.nan] * self.n_cat2vec_feature\n",
    "                    \n",
    "                col_embeds.append(avg_embeds)\n",
    "            col_embeds = pd.DataFrame(col_embeds, columns=[f'{col}_{i}' for i in range(self.n_cat2vec_feature)])\n",
    "            encoded_features = pd.concat([encoded_features, col_embeds], axis=1)\n",
    "\n",
    "        return encoded_features\n",
    "\n",
    "    \n",
    "class Preprocesser:\n",
    "    def __init__(self, \n",
    "                    mulpiple_cat_features: list,\n",
    "                    skewed_num_features: list,\n",
    "                    text_features: list,\n",
    "                    cat_features: list,\n",
    "                    mltpl_cat_n_top: dict,\n",
    "                    n_cat2vec_feature: int, \n",
    "                    n_cat2vec_window: int,\n",
    "                    min_count=1):\n",
    "        self.mulpiple_cat_features = mulpiple_cat_features\n",
    "        self.skewed_num_features = skewed_num_features\n",
    "        self.text_features = text_features\n",
    "        self.mltpl_cat_n_top = mltpl_cat_n_top\n",
    "        self.cat_features = cat_features\n",
    "        \n",
    "        self.cat2vec = Cat2Vec(n_cat2vec_feature, n_cat2vec_window,\n",
    "                               min_count)\n",
    "        \n",
    "    def __get_top_n_mltpl_cat_features(self, df_pr, col):\n",
    "        all_cats = []\n",
    "        for element_values in df_pr[col]:\n",
    "            all_cats.extend(element_values)\n",
    "        return Counter(all_cats).most_common(self.mltpl_cat_n_top[col])\n",
    "            \n",
    "    def __preprocess_mulpiple_cat_features(self, df_pr):\n",
    "        features = self.cat2vec.transform(df_pr[self.mulpiple_cat_features])\n",
    "        # print('features')\n",
    "        # print(features.isnull().sum())\n",
    "        # print('df_pr')\n",
    "        df_pr[features.columns] = features\n",
    "        # print(df_pr.isnull().sum())\n",
    "        df_pr.drop(self.mulpiple_cat_features, axis=1, inplace=True)\n",
    "        \n",
    "        return df_pr\n",
    "    \n",
    "    def __preprocess_skewed_num_features(self, df_pr):\n",
    "        for col in self.skewed_num_features:\n",
    "            df_pr[col] = df_pr[col].apply(lambda x: np.log1p(x))\n",
    "        return df_pr\n",
    "    \n",
    "    def __preprocess_text_features(self, df_pr):\n",
    "        for col in self.text_features:\n",
    "            df_pr[[f'{col}_{i}' for i in range(768)]] = self.embed_model.encode(df_pr[col].values)\n",
    "            df_pr.drop(col, axis=1, inplace=True)\n",
    "        return df_pr\n",
    "    \n",
    "    def __get_unique_values(self, feature):\n",
    "        unique_values = []\n",
    "        for element in feature.dropna():\n",
    "            unique_values.extend(element)\n",
    "        return set(unique_values)\n",
    "    \n",
    "    def __preprocess_cat_features(self, df_pr):\n",
    "        for col in self.cat_features:\n",
    "            unique_values = self.__get_unique_values(df_pr[col])\n",
    "            cats_df = pd.DataFrame(np.full((len(df_pr), len(unique_values)),\n",
    "                                            0),\n",
    "                                   columns=list(unique_values))\n",
    "            \n",
    "            for i, element in enumerate(df_pr[col]):\n",
    "                if isinstance(element, float):\n",
    "                    cats_df.loc[i, :] = 'Na'\n",
    "                    continue\n",
    "                for value in element:\n",
    "                    cats_df.loc[i, value] = '1'\n",
    "            df_pr.drop(col, axis=1, inplace=True)\n",
    "        df_pr[cats_df.columns] = cats_df\n",
    "        return df_pr  \n",
    "            \n",
    "    def fit(self, \n",
    "            df: pd.DataFrame):\n",
    "        self.cat2vec.fit(df[self.mulpiple_cat_features])\n",
    "        \n",
    "    def preprocess(self,\n",
    "                   df: pd.DataFrame):\n",
    "        df_pr = df.copy()\n",
    "        df_pr = self.__preprocess_mulpiple_cat_features(df_pr)\n",
    "        df_pr = self.__preprocess_skewed_num_features(df_pr)\n",
    "        df_pr = self.__preprocess_cat_features(df_pr)\n",
    "        \n",
    "        return df_pr\n",
    "        \n",
    "        \n",
    "class TargetTransformer:\n",
    "    def __init__(self, denominator=1):\n",
    "        self.scale = denominator\n",
    "        \n",
    "    def inverse_transform(self, feature):\n",
    "        return feature.apply(lambda x: np.expm1(x))\n",
    "    \n",
    "    def transform(self, feature):\n",
    "        return feature.apply(lambda x: np.log1p(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e749d2b-3ed6-4334-8878-f86a2fbb28ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# min_count=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8811fd3e-b82e-4b41-a269-981c84de9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mltpl_cat_features = ['actor', 'country', 'genre', 'director']\n",
    "cat_features = ['availability']\n",
    "num_features = ['age_access_type', 'average_rating', 'duration']\n",
    "skewed_num_features = ['duration']\n",
    "text_features = ['name']\n",
    "mltpl_cat_n_top = {'actor': 5, 'country': 1, 'genre': 3, 'director': 1}\n",
    "\n",
    "cat_cols = ['actor', 'genre', 'director']\n",
    "n_cat2vec_feature  = len(cat_cols) * 2 # define the cat2vecs dimentions\n",
    "n_cat2vec_window   = len(cat_cols) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "093f59ed-a295-450f-8ba6-56b1e9c16ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesser = Preprocesser(mltpl_cat_features,\n",
    "            skewed_num_features,\n",
    "            text_features,\n",
    "            cat_features,\n",
    "            mltpl_cat_n_top,\n",
    "            n_cat2vec_feature, \n",
    "            n_cat2vec_window,\n",
    "            min_count=2)\n",
    "\n",
    "target_transformer = TargetTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a40adb31-bf39-49fa-b730-408f2419cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modern = df[df['release_year'] >= 2000]\n",
    "df_short = df_modern[df_modern['target'] < 0.02]\n",
    "df_short.reset_index(drop=True, inplace=True)\n",
    "preprocesser.fit(df_short)\n",
    "df_pr = preprocesser.preprocess(df_short)\n",
    "\n",
    "df_pr.drop('FVOD', axis=1, inplace=True)\n",
    "df_pr['release_year'] = df_pr['release_year'].astype(str)\n",
    "df_pr['average_rating'] = df_pr['average_rating'].astype(float)\n",
    "df_pr['age_access_type'] = df_pr['age_access_type'].astype(int)\n",
    "df_pr['subscription_only'] = df_pr['subscription_only'].apply(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0bdc29fe-08a0-4fde-bb28-8c012ba465f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_access_type         0\n",
       "average_rating        525\n",
       "duration                0\n",
       "type                    0\n",
       "name                    0\n",
       "release_year            0\n",
       "target                  0\n",
       "subscription_only       0\n",
       "uid                     0\n",
       "actor_0               752\n",
       "actor_1               752\n",
       "actor_2               752\n",
       "actor_3               752\n",
       "actor_4               752\n",
       "actor_5               752\n",
       "country_0               2\n",
       "country_1               2\n",
       "country_2               2\n",
       "country_3               2\n",
       "country_4               2\n",
       "country_5               2\n",
       "genre_0                 0\n",
       "genre_1                 0\n",
       "genre_2                 0\n",
       "genre_3                 0\n",
       "genre_4                 0\n",
       "genre_5                 0\n",
       "director_0           3572\n",
       "director_1           3572\n",
       "director_2           3572\n",
       "director_3           3572\n",
       "director_4           3572\n",
       "director_5           3572\n",
       "SUBSCRIPTION            0\n",
       "DTO                     0\n",
       "RENT                    0\n",
       "AVOD                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8e7cdb75-ba2b-4683-9e8f-320df1cc6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['type', 'subscription_only', \n",
    "                'SUBSCRIPTION', 'AVOD', 'DTO',\n",
    "                'RENT', 'release_year']\n",
    "num_features = ['age_access_type', 'average_rating', 'duration']\n",
    "\n",
    "df_pr[cat_features] = df_pr[cat_features].replace(np.nan, 'Na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "93391184-c909-4a6b-822c-3ab1d5f0dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIPLIER = 100\n",
    "X, y = df_pr.drop(['target', 'name', 'uid'], axis=1), df_pr['target']  * MULTIPLIER\n",
    "y = target_transformer.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b5c16c7d-2421-4f6e-9cfd-d943e15479d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_2.pkl', 'wb') as f:\n",
    "    pickle.dump(df_pr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dfd6684d-60d7-4143-9a01-8e89c6ddef6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_access_type</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>release_year</th>\n",
       "      <th>target</th>\n",
       "      <th>subscription_only</th>\n",
       "      <th>uid</th>\n",
       "      <th>actor_0</th>\n",
       "      <th>...</th>\n",
       "      <th>director_0</th>\n",
       "      <th>director_1</th>\n",
       "      <th>director_2</th>\n",
       "      <th>director_3</th>\n",
       "      <th>director_4</th>\n",
       "      <th>director_5</th>\n",
       "      <th>SUBSCRIPTION</th>\n",
       "      <th>DTO</th>\n",
       "      <th>RENT</th>\n",
       "      <th>AVOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.607270</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>В поисках древнего артефакта</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>11ba66db-e941-4c3a-8da6-d8900e56f8c7</td>\n",
       "      <td>-0.048132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146553</td>\n",
       "      <td>0.086444</td>\n",
       "      <td>0.181065</td>\n",
       "      <td>-0.175414</td>\n",
       "      <td>0.169276</td>\n",
       "      <td>0.104724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>6.99</td>\n",
       "      <td>15.145235</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Прожарка Чарли Шина</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>1</td>\n",
       "      <td>3f30a2ef-53b7-40e3-954f-1bdfc38a6d17</td>\n",
       "      <td>-0.063862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096604</td>\n",
       "      <td>0.208678</td>\n",
       "      <td>0.257821</td>\n",
       "      <td>-0.084255</td>\n",
       "      <td>0.145304</td>\n",
       "      <td>0.262974</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>6.00</td>\n",
       "      <td>15.145235</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Прожарка Уильяма Шэтнера</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1</td>\n",
       "      <td>cdfa700f-122d-41e5-b8dc-9c6813bab6d2</td>\n",
       "      <td>-0.094405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096604</td>\n",
       "      <td>0.208678</td>\n",
       "      <td>0.257821</td>\n",
       "      <td>-0.084255</td>\n",
       "      <td>0.145304</td>\n",
       "      <td>0.262974</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6.21</td>\n",
       "      <td>15.396549</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Большое путешествие</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1</td>\n",
       "      <td>d8b55146-dee5-4498-957c-5614414b48fb</td>\n",
       "      <td>-0.079006</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6.40</td>\n",
       "      <td>15.523889</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Пламенное сердце</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>1</td>\n",
       "      <td>ba6bec1a-3aa9-48c7-aa65-908c21627a12</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>16</td>\n",
       "      <td>7.60</td>\n",
       "      <td>18.121735</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Учёный, гуляющий по ночам</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0</td>\n",
       "      <td>f4b8a993-5d91-41f4-b5fb-3769a73d4b53</td>\n",
       "      <td>-0.071564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119466</td>\n",
       "      <td>0.063323</td>\n",
       "      <td>0.123950</td>\n",
       "      <td>-0.150059</td>\n",
       "      <td>0.144995</td>\n",
       "      <td>0.249488</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.184185</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Милые обманщицы: Первородный грех</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>1</td>\n",
       "      <td>673a98a8-5d12-4a3d-9c50-d1d196a8fd96</td>\n",
       "      <td>-0.052503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116897</td>\n",
       "      <td>-0.096789</td>\n",
       "      <td>0.075730</td>\n",
       "      <td>0.020192</td>\n",
       "      <td>-0.100348</td>\n",
       "      <td>0.097352</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>16</td>\n",
       "      <td>7.80</td>\n",
       "      <td>17.627492</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Пропавшие: Другая сторона</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0</td>\n",
       "      <td>37305c51-cb1e-4ff2-b5ad-3425ed73b17a</td>\n",
       "      <td>-0.076522</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.358686</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Тиндер-80</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>1</td>\n",
       "      <td>249b3db3-8dbd-4a18-bd4b-5d0cc08878c4</td>\n",
       "      <td>-0.014324</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Царевны</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0</td>\n",
       "      <td>ca50fd7c-41c5-4208-9f72-06d78fc602b5</td>\n",
       "      <td>-0.028069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081790</td>\n",
       "      <td>-0.095412</td>\n",
       "      <td>0.115728</td>\n",
       "      <td>-0.148281</td>\n",
       "      <td>0.074169</td>\n",
       "      <td>0.246933</td>\n",
       "      <td>Na</td>\n",
       "      <td>Na</td>\n",
       "      <td>Na</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9483 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_access_type  average_rating   duration    type  \\\n",
       "0                  18            4.00  15.607270   MOVIE   \n",
       "1                  18            6.99  15.145235   MOVIE   \n",
       "2                  18            6.00  15.145235   MOVIE   \n",
       "3                   0            6.21  15.396549   MOVIE   \n",
       "4                   6            6.40  15.523889   MOVIE   \n",
       "...               ...             ...        ...     ...   \n",
       "9478               16            7.60  18.121735  SERIAL   \n",
       "9479               18             NaN  17.184185  SERIAL   \n",
       "9480               16            7.80  17.627492  SERIAL   \n",
       "9481               16             NaN  16.358686  SERIAL   \n",
       "9482                0            6.30   0.000000  SERIAL   \n",
       "\n",
       "                                   name release_year    target  \\\n",
       "0          В поисках древнего артефакта         2019  0.000004   \n",
       "1                   Прожарка Чарли Шина         2011  0.000354   \n",
       "2              Прожарка Уильяма Шэтнера         2006  0.000064   \n",
       "3                   Большое путешествие         2006  0.000003   \n",
       "4                      Пламенное сердце         2022  0.009705   \n",
       "...                                 ...          ...       ...   \n",
       "9478          Учёный, гуляющий по ночам         2015  0.000085   \n",
       "9479  Милые обманщицы: Первородный грех         2022  0.000696   \n",
       "9480          Пропавшие: Другая сторона         2020  0.000652   \n",
       "9481                          Тиндер-80         2020  0.001266   \n",
       "9482                            Царевны         2018  0.000786   \n",
       "\n",
       "     subscription_only                                   uid   actor_0  ...  \\\n",
       "0                    0  11ba66db-e941-4c3a-8da6-d8900e56f8c7 -0.048132  ...   \n",
       "1                    1  3f30a2ef-53b7-40e3-954f-1bdfc38a6d17 -0.063862  ...   \n",
       "2                    1  cdfa700f-122d-41e5-b8dc-9c6813bab6d2 -0.094405  ...   \n",
       "3                    1  d8b55146-dee5-4498-957c-5614414b48fb -0.079006  ...   \n",
       "4                    1  ba6bec1a-3aa9-48c7-aa65-908c21627a12 -0.023747  ...   \n",
       "...                ...                                   ...       ...  ...   \n",
       "9478                 0  f4b8a993-5d91-41f4-b5fb-3769a73d4b53 -0.071564  ...   \n",
       "9479                 1  673a98a8-5d12-4a3d-9c50-d1d196a8fd96 -0.052503  ...   \n",
       "9480                 0  37305c51-cb1e-4ff2-b5ad-3425ed73b17a -0.076522  ...   \n",
       "9481                 1  249b3db3-8dbd-4a18-bd4b-5d0cc08878c4 -0.014324  ...   \n",
       "9482                 0  ca50fd7c-41c5-4208-9f72-06d78fc602b5 -0.028069  ...   \n",
       "\n",
       "      director_0  director_1  director_2  director_3  director_4  director_5  \\\n",
       "0       0.146553    0.086444    0.181065   -0.175414    0.169276    0.104724   \n",
       "1      -0.096604    0.208678    0.257821   -0.084255    0.145304    0.262974   \n",
       "2      -0.096604    0.208678    0.257821   -0.084255    0.145304    0.262974   \n",
       "3            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4            NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "9478    0.119466    0.063323    0.123950   -0.150059    0.144995    0.249488   \n",
       "9479    0.116897   -0.096789    0.075730    0.020192   -0.100348    0.097352   \n",
       "9480         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "9481         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "9482   -0.081790   -0.095412    0.115728   -0.148281    0.074169    0.246933   \n",
       "\n",
       "      SUBSCRIPTION  DTO  RENT  AVOD  \n",
       "0                1    1     1     0  \n",
       "1                1    0     0     0  \n",
       "2                1    0     0     0  \n",
       "3                1    0     0     0  \n",
       "4                1    0     0     0  \n",
       "...            ...  ...   ...   ...  \n",
       "9478             1    1     0     0  \n",
       "9479             1    0     0     0  \n",
       "9480             1    0     0     1  \n",
       "9481             1    0     0     0  \n",
       "9482            Na   Na    Na    Na  \n",
       "\n",
       "[9483 rows x 37 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62932547-de61-4d2d-89f9-d0a431dddeff",
   "metadata": {},
   "source": [
    "# min_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d577b7f0-4060-47ae-b2fb-312fb85cbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesser = Preprocesser(mltpl_cat_features,\n",
    "            skewed_num_features,\n",
    "            text_features,\n",
    "            cat_features,\n",
    "            mltpl_cat_n_top,\n",
    "            n_cat2vec_feature, \n",
    "            n_cat2vec_window,\n",
    "            min_count=1)\n",
    "\n",
    "target_transformer = TargetTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c79fb8e2-da07-462e-8df4-b7ba9585a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modern = df[df['release_year'] >= 2000]\n",
    "df_short = df_modern[df_modern['target'] < 0.02]\n",
    "df_short.reset_index(drop=True, inplace=True)\n",
    "preprocesser.fit(df_short)\n",
    "df_pr = preprocesser.preprocess(df_short)\n",
    "\n",
    "df_pr.drop('FVOD', axis=1, inplace=True)\n",
    "df_pr['release_year'] = df_pr['release_year'].astype(str)\n",
    "df_pr['average_rating'] = df_pr['average_rating'].astype(float)\n",
    "df_pr['age_access_type'] = df_pr['age_access_type'].astype(int)\n",
    "df_pr['subscription_only'] = df_pr['subscription_only'].apply(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ea2b8117-54d1-42c1-bdd4-4729d2056811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_access_type</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>release_year</th>\n",
       "      <th>target</th>\n",
       "      <th>subscription_only</th>\n",
       "      <th>uid</th>\n",
       "      <th>actor_0</th>\n",
       "      <th>...</th>\n",
       "      <th>director_0</th>\n",
       "      <th>director_1</th>\n",
       "      <th>director_2</th>\n",
       "      <th>director_3</th>\n",
       "      <th>director_4</th>\n",
       "      <th>director_5</th>\n",
       "      <th>SUBSCRIPTION</th>\n",
       "      <th>DTO</th>\n",
       "      <th>RENT</th>\n",
       "      <th>AVOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.607270</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>В поисках древнего артефакта</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>11ba66db-e941-4c3a-8da6-d8900e56f8c7</td>\n",
       "      <td>-0.030709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005546</td>\n",
       "      <td>0.034927</td>\n",
       "      <td>0.179571</td>\n",
       "      <td>0.139724</td>\n",
       "      <td>0.066432</td>\n",
       "      <td>0.127680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>6.99</td>\n",
       "      <td>15.145235</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Прожарка Чарли Шина</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>1</td>\n",
       "      <td>3f30a2ef-53b7-40e3-954f-1bdfc38a6d17</td>\n",
       "      <td>0.033636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139757</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.156753</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>0.036343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>6.00</td>\n",
       "      <td>15.145235</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Прожарка Уильяма Шэтнера</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1</td>\n",
       "      <td>cdfa700f-122d-41e5-b8dc-9c6813bab6d2</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139757</td>\n",
       "      <td>-0.044668</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.156753</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>0.036343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6.21</td>\n",
       "      <td>15.396549</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Большое путешествие</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1</td>\n",
       "      <td>d8b55146-dee5-4498-957c-5614414b48fb</td>\n",
       "      <td>-0.028783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058414</td>\n",
       "      <td>-0.088417</td>\n",
       "      <td>0.085593</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>-0.128328</td>\n",
       "      <td>0.077235</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6.40</td>\n",
       "      <td>15.523889</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Пламенное сердце</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>1</td>\n",
       "      <td>ba6bec1a-3aa9-48c7-aa65-908c21627a12</td>\n",
       "      <td>-0.034545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063541</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>0.107477</td>\n",
       "      <td>0.056392</td>\n",
       "      <td>0.063167</td>\n",
       "      <td>-0.011712</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>16</td>\n",
       "      <td>7.60</td>\n",
       "      <td>18.121735</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Учёный, гуляющий по ночам</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0</td>\n",
       "      <td>f4b8a993-5d91-41f4-b5fb-3769a73d4b53</td>\n",
       "      <td>-0.017683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057429</td>\n",
       "      <td>-0.090846</td>\n",
       "      <td>-0.073086</td>\n",
       "      <td>0.031009</td>\n",
       "      <td>0.168534</td>\n",
       "      <td>0.051915</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.184185</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Милые обманщицы: Первородный грех</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>1</td>\n",
       "      <td>673a98a8-5d12-4a3d-9c50-d1d196a8fd96</td>\n",
       "      <td>-0.029495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060532</td>\n",
       "      <td>-0.078773</td>\n",
       "      <td>-0.030466</td>\n",
       "      <td>-0.036163</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.017278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>16</td>\n",
       "      <td>7.80</td>\n",
       "      <td>17.627492</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Пропавшие: Другая сторона</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0</td>\n",
       "      <td>37305c51-cb1e-4ff2-b5ad-3425ed73b17a</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043079</td>\n",
       "      <td>0.042460</td>\n",
       "      <td>0.052136</td>\n",
       "      <td>-0.155240</td>\n",
       "      <td>0.118663</td>\n",
       "      <td>0.167637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.358686</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Тиндер-80</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>1</td>\n",
       "      <td>249b3db3-8dbd-4a18-bd4b-5d0cc08878c4</td>\n",
       "      <td>-0.001560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107688</td>\n",
       "      <td>0.112130</td>\n",
       "      <td>0.068875</td>\n",
       "      <td>-0.118909</td>\n",
       "      <td>-0.016524</td>\n",
       "      <td>-0.025074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>Царевны</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0</td>\n",
       "      <td>ca50fd7c-41c5-4208-9f72-06d78fc602b5</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018039</td>\n",
       "      <td>0.029775</td>\n",
       "      <td>-0.019808</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>-0.093366</td>\n",
       "      <td>-0.079711</td>\n",
       "      <td>Na</td>\n",
       "      <td>Na</td>\n",
       "      <td>Na</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9483 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_access_type  average_rating   duration    type  \\\n",
       "0                  18            4.00  15.607270   MOVIE   \n",
       "1                  18            6.99  15.145235   MOVIE   \n",
       "2                  18            6.00  15.145235   MOVIE   \n",
       "3                   0            6.21  15.396549   MOVIE   \n",
       "4                   6            6.40  15.523889   MOVIE   \n",
       "...               ...             ...        ...     ...   \n",
       "9478               16            7.60  18.121735  SERIAL   \n",
       "9479               18             NaN  17.184185  SERIAL   \n",
       "9480               16            7.80  17.627492  SERIAL   \n",
       "9481               16             NaN  16.358686  SERIAL   \n",
       "9482                0            6.30   0.000000  SERIAL   \n",
       "\n",
       "                                   name release_year    target  \\\n",
       "0          В поисках древнего артефакта         2019  0.000004   \n",
       "1                   Прожарка Чарли Шина         2011  0.000354   \n",
       "2              Прожарка Уильяма Шэтнера         2006  0.000064   \n",
       "3                   Большое путешествие         2006  0.000003   \n",
       "4                      Пламенное сердце         2022  0.009705   \n",
       "...                                 ...          ...       ...   \n",
       "9478          Учёный, гуляющий по ночам         2015  0.000085   \n",
       "9479  Милые обманщицы: Первородный грех         2022  0.000696   \n",
       "9480          Пропавшие: Другая сторона         2020  0.000652   \n",
       "9481                          Тиндер-80         2020  0.001266   \n",
       "9482                            Царевны         2018  0.000786   \n",
       "\n",
       "     subscription_only                                   uid   actor_0  ...  \\\n",
       "0                    0  11ba66db-e941-4c3a-8da6-d8900e56f8c7 -0.030709  ...   \n",
       "1                    1  3f30a2ef-53b7-40e3-954f-1bdfc38a6d17  0.033636  ...   \n",
       "2                    1  cdfa700f-122d-41e5-b8dc-9c6813bab6d2  0.004407  ...   \n",
       "3                    1  d8b55146-dee5-4498-957c-5614414b48fb -0.028783  ...   \n",
       "4                    1  ba6bec1a-3aa9-48c7-aa65-908c21627a12 -0.034545  ...   \n",
       "...                ...                                   ...       ...  ...   \n",
       "9478                 0  f4b8a993-5d91-41f4-b5fb-3769a73d4b53 -0.017683  ...   \n",
       "9479                 1  673a98a8-5d12-4a3d-9c50-d1d196a8fd96 -0.029495  ...   \n",
       "9480                 0  37305c51-cb1e-4ff2-b5ad-3425ed73b17a  0.009376  ...   \n",
       "9481                 1  249b3db3-8dbd-4a18-bd4b-5d0cc08878c4 -0.001560  ...   \n",
       "9482                 0  ca50fd7c-41c5-4208-9f72-06d78fc602b5  0.007531  ...   \n",
       "\n",
       "      director_0  director_1  director_2  director_3  director_4  director_5  \\\n",
       "0      -0.005546    0.034927    0.179571    0.139724    0.066432    0.127680   \n",
       "1      -0.139757   -0.044668    0.109483    0.156753   -0.002948    0.036343   \n",
       "2      -0.139757   -0.044668    0.109483    0.156753   -0.002948    0.036343   \n",
       "3      -0.058414   -0.088417    0.085593    0.010822   -0.128328    0.077235   \n",
       "4      -0.063541    0.019863    0.107477    0.056392    0.063167   -0.011712   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "9478   -0.057429   -0.090846   -0.073086    0.031009    0.168534    0.051915   \n",
       "9479    0.060532   -0.078773   -0.030466   -0.036163    0.034507    0.017278   \n",
       "9480   -0.043079    0.042460    0.052136   -0.155240    0.118663    0.167637   \n",
       "9481    0.107688    0.112130    0.068875   -0.118909   -0.016524   -0.025074   \n",
       "9482    0.018039    0.029775   -0.019808    0.021012   -0.093366   -0.079711   \n",
       "\n",
       "      SUBSCRIPTION  DTO  RENT  AVOD  \n",
       "0                1    1     1     0  \n",
       "1                1    0     0     0  \n",
       "2                1    0     0     0  \n",
       "3                1    0     0     0  \n",
       "4                1    0     0     0  \n",
       "...            ...  ...   ...   ...  \n",
       "9478             1    1     0     0  \n",
       "9479             1    0     0     0  \n",
       "9480             1    0     0     1  \n",
       "9481             1    0     0     0  \n",
       "9482            Na   Na    Na    Na  \n",
       "\n",
       "[9483 rows x 37 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4d24b800-01a3-44fe-a8d6-448b01792762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_access_type        0\n",
       "average_rating       525\n",
       "duration               0\n",
       "type                   0\n",
       "name                   0\n",
       "release_year           0\n",
       "target                 0\n",
       "subscription_only      0\n",
       "uid                    0\n",
       "actor_0                0\n",
       "actor_1                0\n",
       "actor_2                0\n",
       "actor_3                0\n",
       "actor_4                0\n",
       "actor_5                0\n",
       "country_0              0\n",
       "country_1              0\n",
       "country_2              0\n",
       "country_3              0\n",
       "country_4              0\n",
       "country_5              0\n",
       "genre_0                0\n",
       "genre_1                0\n",
       "genre_2                0\n",
       "genre_3                0\n",
       "genre_4                0\n",
       "genre_5                0\n",
       "director_0             0\n",
       "director_1             0\n",
       "director_2             0\n",
       "director_3             0\n",
       "director_4             0\n",
       "director_5             0\n",
       "SUBSCRIPTION           0\n",
       "DTO                    0\n",
       "RENT                   0\n",
       "AVOD                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7fc22471-0ce9-4cc9-a6f2-24218acfd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['type', 'subscription_only', \n",
    "                'SUBSCRIPTION', 'AVOD', 'DTO',\n",
    "                'RENT', 'release_year']\n",
    "\n",
    "df_pr[cat_features] = df_pr[cat_features].replace(np.nan, 'Na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1da99df8-51c2-40f4-ae00-d24ab73bb7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIPLIER = 100\n",
    "X, y = df_pr.drop(['target', 'name', 'uid'], axis=1), df_pr['target']  * MULTIPLIER\n",
    "y = target_transformer.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f8d06685-b71e-496a-b30d-e2cf3fa4e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_2_1.pkl', 'wb') as f:\n",
    "    pickle.dump(df_pr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b33ac-8992-41aa-97e2-48f19db0a9fe",
   "metadata": {},
   "source": [
    "# cat2vwc kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "739f7f48-275b-4cca-957f-a20f7c8efd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mulpiple_cat_features = ['country_x', 'ACTOR', 'COMPOSER', 'DIRECTOR',\n",
    "           'EDITOR', 'OPERATOR', 'PRODUCER', 'WRITER']\n",
    "\n",
    "cat_feature_tfidf = 'genre_x'\n",
    "\n",
    "class Cat2Vec:\n",
    "    def __init__(self, n_cat2vec_feature,\n",
    "                    n_cat2vec_window):\n",
    "        self.n_cat2vec_feature = n_cat2vec_feature\n",
    "        self.n_cat2vec_window = n_cat2vec_window\n",
    "    \n",
    "    def __create_tokens(self, col_name, values):\n",
    "        return [f'{col_name} {value}' for value in values]\n",
    "    \n",
    "    def __gen_cat2vec_sentences(self, data):\n",
    "        items = []\n",
    "\n",
    "        for i, row in data.iterrows():\n",
    "            item_values = []\n",
    "            for col, values in zip(row.index, row.values):\n",
    "                item_values.extend(self.__create_tokens(col, values))\n",
    "            shuffle(item_values)\n",
    "            items.append(item_values)\n",
    "        return items\n",
    "    \n",
    "    def fit(self, cat_features):\n",
    "        X_w2v = self.__gen_cat2vec_sentences(cat_features)\n",
    "        self.model = Word2Vec(X_w2v, vector_size=self.n_cat2vec_feature, \n",
    "                         window=self.n_cat2vec_window, epochs=100, min_count=2)\n",
    "        \n",
    "    def transform(self, cat_features):\n",
    "        encoded_features = pd.DataFrame()\n",
    "        for col in cat_features.columns:\n",
    "            tokens = [self.__create_tokens(col, row) if not isinstance(row, float) else [np.nan] for row in cat_features[col]]\n",
    "            col_embeds = []\n",
    "            for row in tokens:\n",
    "                avg_embeds = np.mean([self.model.wv[token] for token in row if token in self.model.wv.key_to_index], \n",
    "                                          axis=0)\n",
    "                if isinstance(avg_embeds, np.float64):\n",
    "                    avg_embeds = [np.nan] * self.n_cat2vec_feature\n",
    "                    \n",
    "                col_embeds.append(avg_embeds)\n",
    "            col_embeds = pd.DataFrame(col_embeds, columns=[f'{col}_{i}' for i in range(self.n_cat2vec_feature)])\n",
    "            encoded_features = pd.concat([encoded_features, col_embeds], axis=1)\n",
    "\n",
    "        return encoded_features\n",
    "        \n",
    "        \n",
    "class Preprocesser:\n",
    "    def __init__(self, \n",
    "                    mulpiple_cat_features: list,\n",
    "                    skewed_num_features: list,\n",
    "                    text_features: list,\n",
    "                    cat_features: list,\n",
    "                    mltpl_cat_n_top: dict,\n",
    "                    cat_feature_tfidf: str):\n",
    "        self.mulpiple_cat_features = mulpiple_cat_features\n",
    "        self.skewed_num_features = skewed_num_features\n",
    "        self.text_features = text_features\n",
    "        self.mltpl_cat_n_top = mltpl_cat_n_top\n",
    "        self.cat_features = cat_features\n",
    "        self.cat_feature_tfidf = cat_feature_tfidf\n",
    "        \n",
    "        self.cat2vec = None\n",
    "        \n",
    "        self.tfidf = TfidfVectorizer(sublinear_tf=True, min_df=50,\n",
    "                                     ngram_range=(1, 1),\n",
    "                                     tokenizer=lambda x: x.split(' '))\n",
    "        \n",
    "        \n",
    "    def __encode_rare(self, df):\n",
    "        for col in self.mulpiple_cat_features:\n",
    "            all_occur = []\n",
    "\n",
    "            for val in df[col]:\n",
    "                if not isinstance(val, float):\n",
    "                    all_occur.extend(val)\n",
    "\n",
    "            all_occur_count = pd.Series(all_occur).value_counts()\n",
    "            rare_items = all_occur_count[all_occur_count == 1].index\n",
    "\n",
    "            new_values = []\n",
    "\n",
    "            for val in df[col]:\n",
    "                if not isinstance(val, float):\n",
    "                    new_values.append(list(set([item if item not in rare_items else 'other' for item in val])))\n",
    "                else:\n",
    "                    new_values.append(np.nan)\n",
    "\n",
    "\n",
    "            df[col] = new_values\n",
    "        return df\n",
    "        \n",
    "    def __get_top_n_mltpl_cat_features(self, df_pr, col):\n",
    "        all_cats = []\n",
    "        for element_values in df_pr[col]:\n",
    "            all_cats.extend(element_values)\n",
    "        return Counter(all_cats).most_common(self.mltpl_cat_n_top[col])\n",
    "            \n",
    "    def __preprocess_mulpiple_cat_features(self, df_pr):\n",
    "        features = self.cat2vec.transform(df_pr[self.mulpiple_cat_features])\n",
    "        df_pr[features.columns] = features\n",
    "        df_pr.drop(self.mulpiple_cat_features, axis=1, inplace=True)\n",
    "        \n",
    "        return df_pr\n",
    "    \n",
    "    def __preprocess_skewed_num_features(self, df_pr):\n",
    "        for col in self.skewed_num_features:\n",
    "            df_pr[col] = df_pr[col].apply(lambda x: np.log1p(x))\n",
    "        return df_pr\n",
    "    \n",
    "    def __preprocess_text_features(self, df_pr):\n",
    "        for col in self.text_features:\n",
    "            df_pr[[f'{col}_{i}' for i in range(768)]] = self.embed_model.encode(df_pr[col].values)\n",
    "            df_pr.drop(col, axis=1, inplace=True)\n",
    "        return df_pr\n",
    "    \n",
    "    def __get_unique_values(self, feature):\n",
    "        unique_values = []\n",
    "        for element in feature.dropna():\n",
    "            unique_values.extend(element)\n",
    "        return set(unique_values)\n",
    "    \n",
    "    def __preprocess_cat_features(self, df_pr):\n",
    "        for col in self.cat_features:\n",
    "            unique_values = self.__get_unique_values(df_pr[col])\n",
    "            cats_df = pd.DataFrame(np.full((len(df_pr), len(unique_values)),\n",
    "                                            0),\n",
    "                                   columns=list(unique_values))\n",
    "            \n",
    "            for i, element in enumerate(df_pr[col]):\n",
    "                if isinstance(element, float):\n",
    "                    cats_df.loc[i, :] = 'Na'\n",
    "                    continue\n",
    "                for value in element:\n",
    "                    cats_df.loc[i, value] = '1'\n",
    "            df_pr.drop(col, axis=1, inplace=True)\n",
    "        df_pr[cats_df.columns] = cats_df\n",
    "        return df_pr  \n",
    "    \n",
    "    def __preprocess_cat_features_tfidf(self, df_pr):\n",
    "        features = self.tfidf.transform(df_pr[self.cat_feature_tfidf].apply(lambda x : ' '.join(x))).toarray()\n",
    "        df_pr[self.tfidf.get_feature_names()] = features\n",
    "\n",
    "        return df_pr.drop(self.cat_feature_tfidf, axis=1)\n",
    "  \n",
    "    def fit(self, df):\n",
    "        self.tfidf.fit(df[self.cat_feature_tfidf].apply(lambda x : ' '.join(x)))\n",
    "        \n",
    "    def preprocess(self,\n",
    "                   df: pd.DataFrame):\n",
    "        df_pr = df.copy()\n",
    "        df_pr = self.__encode_rare(df_pr)\n",
    "        df_pr = self.__preprocess_mulpiple_cat_features(df_pr)\n",
    "        df_pr = self.__preprocess_cat_features_tfidf(df_pr)\n",
    "        \n",
    "        return df_pr\n",
    "    \n",
    "with open('/home/jovyan/work/cat2vec_kp.pkl', 'rb') as f:\n",
    "    cat2vec = pickle.load(f)\n",
    "    \n",
    "preprocesser = Preprocesser(mulpiple_cat_features=mulpiple_cat_features,\n",
    "                    skewed_num_features=[],\n",
    "                    text_features=[],\n",
    "                    cat_features=[],\n",
    "                    mltpl_cat_n_top=[],\n",
    "                    cat_feature_tfidf=cat_feature_tfidf\n",
    "                    )\n",
    "\n",
    "preprocesser.cat2vec = cat2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b998dafe-a4f8-4eb0-a43d-796e65c2e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/work/cold_start_models/item_coldstart_dataset-avg.pkl', 'rb') as f:\n",
    "    df_avg = pickle.load(f)\n",
    "    \n",
    "    \n",
    "with open('/home/jovyan/work/cold_start_models/item_coldstart_dataset_kp.pkl', 'rb') as f:\n",
    "    df_kp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9ed49295-2008-4f4e-9c97-814d5788e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_kp.merge(df_avg, on='uid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b5d88f2e-678b-40c4-bea8-637a7762f2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_access_type_x', 'country_x', 'duration_x', 'availability_x',\n",
       "       'type_x', 'name_x', 'release_year_x', 'genre_x', 'user_count_3months',\n",
       "       'subscription_only_x', 'uid', 'ACTOR', 'COMPOSER', 'DESIGN', 'DIRECTOR',\n",
       "       'EDITOR', 'OPERATOR', 'PRODUCER', 'WRITER', 'BUDGET', 'MARKETING',\n",
       "       'RUS', 'USA', 'WORLD', 'actor', 'age_access_type_y', 'country_y',\n",
       "       'average_rating', 'duration_y', 'availability_y', 'type_y', 'name_y',\n",
       "       'release_year_y', 'genre_y', 'director', 'subscription_only_y',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f5d3e0f7-9bac-418e-adc5-bec5f67711ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['name_x', 'age_access_type_x', 'country_x', 'duration_x', 'type_x',\n",
    "            'release_year_x', 'genre_x', 'ACTOR', 'COMPOSER', 'DIRECTOR',\n",
    "           'EDITOR', 'OPERATOR', 'PRODUCER', 'WRITER', 'BUDGET', 'MARKETING',\n",
    "           'RUS', 'WORLD', 'target', 'uid']\n",
    "\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fc20dd4c-cd68-4793-a8f7-546ba43ff11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name_x', 'age_access_type_x', 'country_x', 'duration_x', 'type_x',\n",
       "       'release_year_x', 'genre_x', 'ACTOR', 'COMPOSER', 'DIRECTOR', 'EDITOR',\n",
       "       'OPERATOR', 'PRODUCER', 'WRITER', 'BUDGET', 'MARKETING', 'RUS', 'WORLD',\n",
       "       'target', 'uid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "99cd87e9-fc3e-4838-8ccf-f03f4ca3d65c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/tmp/ipykernel_14911/574129037.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[features.columns] = features\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n",
      "/tmp/ipykernel_14911/574129037.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_pr[self.tfidf.get_feature_names()] = features\n"
     ]
    }
   ],
   "source": [
    "df_short.reset_index(drop=True, inplace=True)\n",
    "preprocesser.fit(df)\n",
    "df_pr = preprocesser.preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "665e73da-9f67-4adb-9095-2d6bf8ecdc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10017, 225)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "60244954-1cc9-46eb-8890-b08587c9f702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_x</th>\n",
       "      <th>age_access_type_x</th>\n",
       "      <th>duration_x</th>\n",
       "      <th>type_x</th>\n",
       "      <th>release_year_x</th>\n",
       "      <th>BUDGET</th>\n",
       "      <th>MARKETING</th>\n",
       "      <th>RUS</th>\n",
       "      <th>WORLD</th>\n",
       "      <th>target</th>\n",
       "      <th>...</th>\n",
       "      <th>forkids</th>\n",
       "      <th>history</th>\n",
       "      <th>horror</th>\n",
       "      <th>humor</th>\n",
       "      <th>melodrama</th>\n",
       "      <th>music</th>\n",
       "      <th>sci-fi</th>\n",
       "      <th>sport</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war_movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Звёздный путь 5: Последний рубеж</td>\n",
       "      <td>12</td>\n",
       "      <td>6420000.0</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>27800000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52210049.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Звёздный путь 6: Неоткрытая страна</td>\n",
       "      <td>16</td>\n",
       "      <td>6780000.0</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96888996.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В поисках древнего артефакта</td>\n",
       "      <td>18</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Прожарка Чарли Шина</td>\n",
       "      <td>18</td>\n",
       "      <td>3780000.0</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Прожарка Уильяма Шэтнера</td>\n",
       "      <td>18</td>\n",
       "      <td>3780000.0</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>Эрнест и Селестина</td>\n",
       "      <td>0</td>\n",
       "      <td>36300000.0</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>Мульт \"Кухня\"</td>\n",
       "      <td>16</td>\n",
       "      <td>29040000.0</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>Без памяти</td>\n",
       "      <td>12</td>\n",
       "      <td>12240000.0</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>Всплеск любви</td>\n",
       "      <td>16</td>\n",
       "      <td>8400000.0</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>990.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016</th>\n",
       "      <td>Царевны</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SERIAL</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10017 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name_x age_access_type_x  duration_x  \\\n",
       "0        Звёздный путь 5: Последний рубеж                12   6420000.0   \n",
       "1      Звёздный путь 6: Неоткрытая страна                16   6780000.0   \n",
       "2            В поисках древнего артефакта                18   6000000.0   \n",
       "3                     Прожарка Чарли Шина                18   3780000.0   \n",
       "4                Прожарка Уильяма Шэтнера                18   3780000.0   \n",
       "...                                   ...               ...         ...   \n",
       "10012                  Эрнест и Селестина                 0  36300000.0   \n",
       "10013                       Мульт \"Кухня\"                16  29040000.0   \n",
       "10014                          Без памяти                12  12240000.0   \n",
       "10015                       Всплеск любви                16   8400000.0   \n",
       "10016                             Царевны                 0         0.0   \n",
       "\n",
       "       type_x  release_year_x      BUDGET  MARKETING  RUS       WORLD  target  \\\n",
       "0       MOVIE          1989.0  27800000.0        NaN  NaN  52210049.0     7.0   \n",
       "1       MOVIE          1991.0  30000000.0        NaN  NaN  96888996.0     7.0   \n",
       "2       MOVIE          2019.0         NaN        NaN  NaN         NaN    32.0   \n",
       "3       MOVIE          2011.0         NaN        NaN  NaN         NaN   122.0   \n",
       "4       MOVIE          2006.0         NaN        NaN  NaN         NaN    25.0   \n",
       "...       ...             ...         ...        ...  ...         ...     ...   \n",
       "10012  SERIAL          2017.0         NaN        NaN  NaN         NaN   729.0   \n",
       "10013  SERIAL          2017.0         NaN        NaN  NaN         NaN    17.0   \n",
       "10014  SERIAL          2021.0         NaN        NaN  NaN         NaN  7164.0   \n",
       "10015  SERIAL          2015.0         NaN        NaN  NaN         NaN   990.0   \n",
       "10016  SERIAL          2018.0         NaN        NaN  NaN         NaN  2092.0   \n",
       "\n",
       "       ... forkids  history  horror  humor  melodrama  music    sci-fi  sport  \\\n",
       "0      ...     0.0      0.0     0.0    0.0   0.000000    0.0  0.564117    0.0   \n",
       "1      ...     0.0      0.0     0.0    0.0   0.000000    0.0  0.564117    0.0   \n",
       "2      ...     0.0      0.0     1.0    0.0   0.000000    0.0  0.000000    0.0   \n",
       "3      ...     0.0      0.0     0.0    0.0   0.000000    0.0  0.000000    0.0   \n",
       "4      ...     0.0      0.0     0.0    0.0   0.000000    0.0  0.000000    0.0   \n",
       "...    ...     ...      ...     ...    ...        ...    ...       ...    ...   \n",
       "10012  ...     0.0      0.0     0.0    0.0   0.000000    0.0  0.000000    0.0   \n",
       "10013  ...     0.0      0.0     0.0    0.0   0.000000    0.0  0.000000    0.0   \n",
       "10014  ...     0.0      0.0     0.0    0.0   0.804481    0.0  0.000000    0.0   \n",
       "10015  ...     0.0      0.0     0.0    0.0   0.634899    0.0  0.000000    0.0   \n",
       "10016  ...     0.0      0.0     0.0    0.0   0.000000    0.0  0.000000    0.0   \n",
       "\n",
       "       thriller  war_movies  \n",
       "0      0.436822         0.0  \n",
       "1      0.436822         0.0  \n",
       "2      0.000000         0.0  \n",
       "3      0.000000         0.0  \n",
       "4      0.000000         0.0  \n",
       "...         ...         ...  \n",
       "10012  0.000000         0.0  \n",
       "10013  0.000000         0.0  \n",
       "10014  0.000000         0.0  \n",
       "10015  0.000000         0.0  \n",
       "10016  0.000000         0.0  \n",
       "\n",
       "[10017 rows x 225 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "46dc9d05-9d1f-46b6-9137-5650e10b37a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name_x',\n",
       " 'age_access_type_x',\n",
       " 'duration_x',\n",
       " 'type_x',\n",
       " 'release_year_x',\n",
       " 'BUDGET',\n",
       " 'MARKETING',\n",
       " 'RUS',\n",
       " 'WORLD',\n",
       " 'target',\n",
       " 'uid',\n",
       " 'country_x_0',\n",
       " 'country_x_1',\n",
       " 'country_x_2',\n",
       " 'country_x_3',\n",
       " 'country_x_4',\n",
       " 'country_x_5',\n",
       " 'country_x_6',\n",
       " 'country_x_7',\n",
       " 'country_x_8',\n",
       " 'country_x_9',\n",
       " 'country_x_10',\n",
       " 'country_x_11',\n",
       " 'country_x_12',\n",
       " 'country_x_13',\n",
       " 'country_x_14',\n",
       " 'country_x_15',\n",
       " 'country_x_16',\n",
       " 'country_x_17',\n",
       " 'country_x_18',\n",
       " 'country_x_19',\n",
       " 'country_x_20',\n",
       " 'country_x_21',\n",
       " 'country_x_22',\n",
       " 'country_x_23',\n",
       " 'ACTOR_0',\n",
       " 'ACTOR_1',\n",
       " 'ACTOR_2',\n",
       " 'ACTOR_3',\n",
       " 'ACTOR_4',\n",
       " 'ACTOR_5',\n",
       " 'ACTOR_6',\n",
       " 'ACTOR_7',\n",
       " 'ACTOR_8',\n",
       " 'ACTOR_9',\n",
       " 'ACTOR_10',\n",
       " 'ACTOR_11',\n",
       " 'ACTOR_12',\n",
       " 'ACTOR_13',\n",
       " 'ACTOR_14',\n",
       " 'ACTOR_15',\n",
       " 'ACTOR_16',\n",
       " 'ACTOR_17',\n",
       " 'ACTOR_18',\n",
       " 'ACTOR_19',\n",
       " 'ACTOR_20',\n",
       " 'ACTOR_21',\n",
       " 'ACTOR_22',\n",
       " 'ACTOR_23',\n",
       " 'COMPOSER_0',\n",
       " 'COMPOSER_1',\n",
       " 'COMPOSER_2',\n",
       " 'COMPOSER_3',\n",
       " 'COMPOSER_4',\n",
       " 'COMPOSER_5',\n",
       " 'COMPOSER_6',\n",
       " 'COMPOSER_7',\n",
       " 'COMPOSER_8',\n",
       " 'COMPOSER_9',\n",
       " 'COMPOSER_10',\n",
       " 'COMPOSER_11',\n",
       " 'COMPOSER_12',\n",
       " 'COMPOSER_13',\n",
       " 'COMPOSER_14',\n",
       " 'COMPOSER_15',\n",
       " 'COMPOSER_16',\n",
       " 'COMPOSER_17',\n",
       " 'COMPOSER_18',\n",
       " 'COMPOSER_19',\n",
       " 'COMPOSER_20',\n",
       " 'COMPOSER_21',\n",
       " 'COMPOSER_22',\n",
       " 'COMPOSER_23',\n",
       " 'DIRECTOR_0',\n",
       " 'DIRECTOR_1',\n",
       " 'DIRECTOR_2',\n",
       " 'DIRECTOR_3',\n",
       " 'DIRECTOR_4',\n",
       " 'DIRECTOR_5',\n",
       " 'DIRECTOR_6',\n",
       " 'DIRECTOR_7',\n",
       " 'DIRECTOR_8',\n",
       " 'DIRECTOR_9',\n",
       " 'DIRECTOR_10',\n",
       " 'DIRECTOR_11',\n",
       " 'DIRECTOR_12',\n",
       " 'DIRECTOR_13',\n",
       " 'DIRECTOR_14',\n",
       " 'DIRECTOR_15',\n",
       " 'DIRECTOR_16',\n",
       " 'DIRECTOR_17',\n",
       " 'DIRECTOR_18',\n",
       " 'DIRECTOR_19',\n",
       " 'DIRECTOR_20',\n",
       " 'DIRECTOR_21',\n",
       " 'DIRECTOR_22',\n",
       " 'DIRECTOR_23',\n",
       " 'EDITOR_0',\n",
       " 'EDITOR_1',\n",
       " 'EDITOR_2',\n",
       " 'EDITOR_3',\n",
       " 'EDITOR_4',\n",
       " 'EDITOR_5',\n",
       " 'EDITOR_6',\n",
       " 'EDITOR_7',\n",
       " 'EDITOR_8',\n",
       " 'EDITOR_9',\n",
       " 'EDITOR_10',\n",
       " 'EDITOR_11',\n",
       " 'EDITOR_12',\n",
       " 'EDITOR_13',\n",
       " 'EDITOR_14',\n",
       " 'EDITOR_15',\n",
       " 'EDITOR_16',\n",
       " 'EDITOR_17',\n",
       " 'EDITOR_18',\n",
       " 'EDITOR_19',\n",
       " 'EDITOR_20',\n",
       " 'EDITOR_21',\n",
       " 'EDITOR_22',\n",
       " 'EDITOR_23',\n",
       " 'OPERATOR_0',\n",
       " 'OPERATOR_1',\n",
       " 'OPERATOR_2',\n",
       " 'OPERATOR_3',\n",
       " 'OPERATOR_4',\n",
       " 'OPERATOR_5',\n",
       " 'OPERATOR_6',\n",
       " 'OPERATOR_7',\n",
       " 'OPERATOR_8',\n",
       " 'OPERATOR_9',\n",
       " 'OPERATOR_10',\n",
       " 'OPERATOR_11',\n",
       " 'OPERATOR_12',\n",
       " 'OPERATOR_13',\n",
       " 'OPERATOR_14',\n",
       " 'OPERATOR_15',\n",
       " 'OPERATOR_16',\n",
       " 'OPERATOR_17',\n",
       " 'OPERATOR_18',\n",
       " 'OPERATOR_19',\n",
       " 'OPERATOR_20',\n",
       " 'OPERATOR_21',\n",
       " 'OPERATOR_22',\n",
       " 'OPERATOR_23',\n",
       " 'PRODUCER_0',\n",
       " 'PRODUCER_1',\n",
       " 'PRODUCER_2',\n",
       " 'PRODUCER_3',\n",
       " 'PRODUCER_4',\n",
       " 'PRODUCER_5',\n",
       " 'PRODUCER_6',\n",
       " 'PRODUCER_7',\n",
       " 'PRODUCER_8',\n",
       " 'PRODUCER_9',\n",
       " 'PRODUCER_10',\n",
       " 'PRODUCER_11',\n",
       " 'PRODUCER_12',\n",
       " 'PRODUCER_13',\n",
       " 'PRODUCER_14',\n",
       " 'PRODUCER_15',\n",
       " 'PRODUCER_16',\n",
       " 'PRODUCER_17',\n",
       " 'PRODUCER_18',\n",
       " 'PRODUCER_19',\n",
       " 'PRODUCER_20',\n",
       " 'PRODUCER_21',\n",
       " 'PRODUCER_22',\n",
       " 'PRODUCER_23',\n",
       " 'WRITER_0',\n",
       " 'WRITER_1',\n",
       " 'WRITER_2',\n",
       " 'WRITER_3',\n",
       " 'WRITER_4',\n",
       " 'WRITER_5',\n",
       " 'WRITER_6',\n",
       " 'WRITER_7',\n",
       " 'WRITER_8',\n",
       " 'WRITER_9',\n",
       " 'WRITER_10',\n",
       " 'WRITER_11',\n",
       " 'WRITER_12',\n",
       " 'WRITER_13',\n",
       " 'WRITER_14',\n",
       " 'WRITER_15',\n",
       " 'WRITER_16',\n",
       " 'WRITER_17',\n",
       " 'WRITER_18',\n",
       " 'WRITER_19',\n",
       " 'WRITER_20',\n",
       " 'WRITER_21',\n",
       " 'WRITER_22',\n",
       " 'WRITER_23',\n",
       " 'action',\n",
       " 'adventure',\n",
       " 'anime',\n",
       " 'biography',\n",
       " 'cartoons',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'detective',\n",
       " 'documentary',\n",
       " 'drama',\n",
       " 'family',\n",
       " 'fantasy',\n",
       " 'forkids',\n",
       " 'history',\n",
       " 'horror',\n",
       " 'humor',\n",
       " 'melodrama',\n",
       " 'music',\n",
       " 'sci-fi',\n",
       " 'sport',\n",
       " 'thriller',\n",
       " 'war_movies']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_pr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5873663f-ea87-48eb-bf9f-e579389c7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_2kp.pkl', 'wb') as f:\n",
    "    pickle.dump(df_pr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d36b3-7ad5-4907-9f73-50e3d2177f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da315d17-689c-4f0a-902a-e71867c15bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
